{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJpi71KghWRL5u9ohpMhvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi25072002/software-engineering-challenges/blob/master/WidsDatathon2024NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Artificial Neural Network + NLP,ensembling method"
      ],
      "metadata": {
        "id": "TFFcKe1n3kEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UD35DJbZ3uAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2PKFUPss3tv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCB2Rrr1_-m",
        "outputId": "c22684b7-c9d6-49a5-e232-b97944e56f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading widsdatathon2024-challenge1.zip to /content\n",
            " 79% 4.00M/5.04M [00:01<00:00, 4.44MB/s]\n",
            "100% 5.04M/5.04M [00:01<00:00, 3.84MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c widsdatathon2024-challenge1"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNaVTpSr_L5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip widsdatathon2024-challenge1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdmLcDf4LBy",
        "outputId": "9ff36198-0cb7-4800-f28a-24f4df9f3d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  widsdatathon2024-challenge1.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: training.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"./training.csv\")\n",
        "test = pd.read_csv(\"./test.csv\")\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())\n",
        "print(train.columns)\n",
        "train.drop(columns = ['patient_id'], inplace= True)\n",
        "test.drop(columns = ['patient_id'], inplace= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GdZoksn4Pp0",
        "outputId": "139469c7-48e9-4e00-e8ce-4a499b354223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patient_id           0\n",
            "patient_race      6385\n",
            "payer_type        1803\n",
            "patient_state       51\n",
            "patient_zip3         0\n",
            "                  ... \n",
            "veteran              1\n",
            "Ozone               29\n",
            "PM25                29\n",
            "N02                 29\n",
            "DiagPeriodL90D       0\n",
            "Length: 83, dtype: int64\n",
            "patient_id             0\n",
            "patient_race        2901\n",
            "payer_type           760\n",
            "patient_state         21\n",
            "patient_zip3           0\n",
            "                    ... \n",
            "health_uninsured       0\n",
            "veteran                0\n",
            "Ozone                 14\n",
            "PM25                  14\n",
            "N02                   14\n",
            "Length: 82, dtype: int64\n",
            "Index(['patient_id', 'patient_race', 'payer_type', 'patient_state',\n",
            "       'patient_zip3', 'patient_age', 'patient_gender', 'bmi',\n",
            "       'breast_cancer_diagnosis_code', 'breast_cancer_diagnosis_desc',\n",
            "       'metastatic_cancer_diagnosis_code', 'metastatic_first_novel_treatment',\n",
            "       'metastatic_first_novel_treatment_type', 'Region', 'Division',\n",
            "       'population', 'density', 'age_median', 'age_under_10', 'age_10_to_19',\n",
            "       'age_20s', 'age_30s', 'age_40s', 'age_50s', 'age_60s', 'age_70s',\n",
            "       'age_over_80', 'male', 'female', 'married', 'divorced', 'never_married',\n",
            "       'widowed', 'family_size', 'family_dual_income',\n",
            "       'income_household_median', 'income_household_under_5',\n",
            "       'income_household_5_to_10', 'income_household_10_to_15',\n",
            "       'income_household_15_to_20', 'income_household_20_to_25',\n",
            "       'income_household_25_to_35', 'income_household_35_to_50',\n",
            "       'income_household_50_to_75', 'income_household_75_to_100',\n",
            "       'income_household_100_to_150', 'income_household_150_over',\n",
            "       'income_household_six_figure', 'income_individual_median',\n",
            "       'home_ownership', 'housing_units', 'home_value', 'rent_median',\n",
            "       'rent_burden', 'education_less_highschool', 'education_highschool',\n",
            "       'education_some_college', 'education_bachelors', 'education_graduate',\n",
            "       'education_college_or_above', 'education_stem_degree',\n",
            "       'labor_force_participation', 'unemployment_rate', 'self_employed',\n",
            "       'farmer', 'race_white', 'race_black', 'race_asian', 'race_native',\n",
            "       'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled',\n",
            "       'poverty', 'limited_english', 'commute_time', 'health_uninsured',\n",
            "       'veteran', 'Ozone', 'PM25', 'N02', 'DiagPeriodL90D'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# describing Training data :\n",
        "desc = pd.DataFrame(index = list(train))\n",
        "desc['type'] = train.dtypes\n",
        "desc['count'] = train.count()\n",
        "desc['nunique'] = train.nunique()\n",
        "desc['%unique'] = desc['nunique'] /len(train) * 100\n",
        "desc['null'] = train.isnull().sum()\n",
        "desc['%null'] = desc['null'] / len(train) * 100\n",
        "desc = pd.concat([desc,train.describe().T.drop('count',axis=1)],axis=1)\n",
        "desc.sort_values(by=['type','null']).style.background_gradient(axis=0)"
      ],
      "metadata": {
        "id": "9fX8HTLe5V4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc = pd.DataFrame(index = list(test))\n",
        "desc['type'] = test.dtypes\n",
        "desc['count'] = test.count()\n",
        "desc['nunique'] = test.nunique()\n",
        "desc['%unique'] = desc['nunique'] /len(test) * 100\n",
        "desc['null'] = test.isnull().sum()\n",
        "desc['%null'] = desc['null'] / len(test) * 100\n",
        "desc = pd.concat([desc,test.describe().T.drop('count',axis=1)],axis=1)\n",
        "desc.sort_values(by=['type','null']).style.background_gradient(axis=0)"
      ],
      "metadata": {
        "id": "OtCf0dnv4pxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define the imputers\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
        "constant_imputer_novel_treatment = SimpleImputer(strategy='constant', fill_value='No')\n",
        "constant_imputer_novel_treatment_type = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
        "constant_imputer_patient_race = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
        "\n",
        "# Impute 'bmi' with median\n",
        "train[['bmi']] = median_imputer.fit_transform(train[['bmi']])\n",
        "\n",
        "# Impute 'patient_race' as 'Unknown'\n",
        "train[['patient_race']] = constant_imputer_patient_race.fit_transform(train[['patient_race']])\n",
        "\n",
        "# Impute 'novel_treatment' as 'No' and 'novel_treatment_type' as 'Unknown'\n",
        "train[['metastatic_first_novel_treatment']] = constant_imputer_novel_treatment.fit_transform(train[['metastatic_first_novel_treatment']])\n",
        "train[['metastatic_first_novel_treatment_type']] = constant_imputer_novel_treatment_type.fit_transform(train[['metastatic_first_novel_treatment_type']])\n",
        "\n",
        "# Impute 'payer_type' with the mode\n",
        "train[['payer_type']] = mode_imputer.fit_transform(train[['payer_type']])\n",
        "\n",
        "# Impute 'region', 'patient_state', and 'division' with the mode\n",
        "columns_to_impute_mode = ['Region', 'patient_state', 'Division']\n",
        "train[columns_to_impute_mode] = mode_imputer.fit_transform(train[columns_to_impute_mode])\n",
        "\n",
        "# Impute 'ozone', 'NO2', 'PM2.5' with the median\n",
        "columns_to_impute_median = ['Ozone', 'N02', 'PM25']\n",
        "train[columns_to_impute_median] = median_imputer.fit_transform(train[columns_to_impute_median])"
      ],
      "metadata": {
        "id": "NB8mRfeC-bvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define the imputers\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
        "constant_imputer_novel_treatment = SimpleImputer(strategy='constant', fill_value='No')\n",
        "constant_imputer_novel_treatment_type = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
        "constant_imputer_patient_race = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
        "\n",
        "# Impute 'bmi' with median\n",
        "test[['bmi']] = median_imputer.fit_transform(test[['bmi']])\n",
        "\n",
        "# Impute 'patient_race' as 'Unknown'\n",
        "test[['patient_race']] = constant_imputer_patient_race.fit_transform(test[['patient_race']])\n",
        "\n",
        "# Impute 'novel_treatment' as 'No' and 'novel_treatment_type' as 'Unknown'\n",
        "test[['metastatic_first_novel_treatment']] = constant_imputer_novel_treatment.fit_transform(test[['metastatic_first_novel_treatment']])\n",
        "test[['metastatic_first_novel_treatment_type']] = constant_imputer_novel_treatment_type.fit_transform(test[['metastatic_first_novel_treatment_type']])\n",
        "\n",
        "# Impute 'payer_type' with the mode\n",
        "test[['payer_type']] = mode_imputer.fit_transform(test[['payer_type']])\n",
        "\n",
        "# Impute 'region', 'patient_state', and 'division' with the mode\n",
        "columns_to_impute_mode = ['Region', 'patient_state', 'Division']\n",
        "test[columns_to_impute_mode] = mode_imputer.fit_transform(test[columns_to_impute_mode])\n",
        "\n",
        "# Impute 'ozone', 'NO2', 'PM2.5' with the median\n",
        "columns_to_impute_median = ['Ozone', 'N02', 'PM25']\n",
        "test[columns_to_impute_median] = median_imputer.fit_transform(test[columns_to_impute_median])"
      ],
      "metadata": {
        "id": "N_bzW6mO_ORV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['patient_zip3'] = train['patient_zip3'].astype('category')\n",
        "test['patient_zip3'] = test['patient_zip3'].astype('category')\n"
      ],
      "metadata": {
        "id": "amCou2hT_bpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in train.columns:\n",
        "    # Check if the column is numerical (int or float)\n",
        "    if train[column].dtype == 'float64' or train[column].dtype == 'int64':\n",
        "        train[column].fillna(train[column].mean(), inplace=True)\n",
        "    # Else, the column is categorical, fill with the mode\n",
        "    else:\n",
        "        train[column].fillna(train[column].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "vV2iDUNcAoCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in test.columns:\n",
        "    # Check if the column is numerical (int or float)\n",
        "    if test[column].dtype == 'float64' or test[column].dtype == 'int64':\n",
        "        test[column].fillna(test[column].mean(), inplace=True)\n",
        "    # Else, the column is categorical, fill with the mode\n",
        "    else:\n",
        "        test[column].fillna(test[column].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "id": "uBbAVmQo_vZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verify if all null values are hanlded in both traina dn test\n",
        "remaining_nulls = train.isnull().sum()\n",
        "print(remaining_nulls[remaining_nulls > 0])\n",
        "remaining_nullst = test.isnull().sum()\n",
        "print(remaining_nullst[remaining_nullst > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkWEN-ioA3n_",
        "outputId": "3efc8a4e-6d6c-4840-8ce1-478e45dfda26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], dtype: int64)\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'train' is your DataFrame and 'numerical_columns' contains the names of all numerical columns\n",
        "numerical_columns = train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Creating boxplots for each numerical column\n",
        "for col in numerical_columns:\n",
        "    plt.figure(figsize=(6, 6))  # Set the figure size for better visibility\n",
        "    sns.boxplot(x=train[col])  # Create a boxplot for the column\n",
        "    plt.title(f'Boxplot of {col}')  # Set the title of the boxplot\n",
        "    plt.xlabel(col)  # Set the x-axis label as the column name\n",
        "    plt.show()  # Display the plot\n"
      ],
      "metadata": {
        "id": "Zf-9Nfv-BNy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'train' is your DataFrame and 'numerical_columns' contains the names of all numerical columns\n",
        "numerical_columns = test.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Creating boxplots for each numerical column\n",
        "for col in numerical_columns:\n",
        "    plt.figure(figsize=(6, 6))  # Set the figure size for better visibility\n",
        "    sns.boxplot(x=test[col])  # Create a boxplot for the column\n",
        "    plt.title(f'Boxplot of {col}')  # Set the title of the boxplot\n",
        "    plt.xlabel(col)  # Set the x-axis label as the column name\n",
        "    plt.show()  # Display the plot\n"
      ],
      "metadata": {
        "id": "bLX5TcDtB6Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_col = []\n",
        "cat_col = []\n",
        "for col in train.columns:\n",
        "    if train[col].dtypes in ['float64' , 'int64']:\n",
        "        num_col.append(col)\n",
        "    else:\n",
        "       cat_col.append(col)\n",
        "print(num_col)\n",
        "print(cat_col)\n",
        "num_col = ['patient_age', 'bmi', 'population', 'density', 'age_median', 'age_under_10', 'age_10_to_19', 'age_20s', 'age_30s', 'age_40s', 'age_50s', 'age_60s', 'age_70s', 'age_over_80', 'male', 'female', 'married', 'divorced', 'never_married', 'widowed', 'family_size', 'family_dual_income', 'income_household_median', 'income_household_under_5', 'income_household_5_to_10', 'income_household_10_to_15', 'income_household_15_to_20', 'income_household_20_to_25', 'income_household_25_to_35', 'income_household_35_to_50', 'income_household_50_to_75', 'income_household_75_to_100', 'income_household_100_to_150', 'income_household_150_over', 'income_household_six_figure', 'income_individual_median', 'home_ownership', 'housing_units', 'home_value', 'rent_median', 'rent_burden', 'education_less_highschool', 'education_highschool', 'education_some_college', 'education_bachelors', 'education_graduate', 'education_college_or_above', 'education_stem_degree', 'labor_force_participation', 'unemployment_rate', 'self_employed', 'farmer', 'race_white', 'race_black', 'race_asian', 'race_native', 'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled', 'poverty', 'limited_english', 'commute_time', 'health_uninsured', 'veteran', 'Ozone', 'PM25', 'N02']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTgBup9MJBsI",
        "outputId": "4fda8c0c-ad08-491d-a2ef-8861a2d261c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['patient_age', 'bmi', 'population', 'density', 'age_median', 'age_under_10', 'age_10_to_19', 'age_20s', 'age_30s', 'age_40s', 'age_50s', 'age_60s', 'age_70s', 'age_over_80', 'male', 'female', 'married', 'divorced', 'never_married', 'widowed', 'family_size', 'family_dual_income', 'income_household_median', 'income_household_under_5', 'income_household_5_to_10', 'income_household_10_to_15', 'income_household_15_to_20', 'income_household_20_to_25', 'income_household_25_to_35', 'income_household_35_to_50', 'income_household_50_to_75', 'income_household_75_to_100', 'income_household_100_to_150', 'income_household_150_over', 'income_household_six_figure', 'income_individual_median', 'home_ownership', 'housing_units', 'home_value', 'rent_median', 'rent_burden', 'education_less_highschool', 'education_highschool', 'education_some_college', 'education_bachelors', 'education_graduate', 'education_college_or_above', 'education_stem_degree', 'labor_force_participation', 'unemployment_rate', 'self_employed', 'farmer', 'race_white', 'race_black', 'race_asian', 'race_native', 'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled', 'poverty', 'limited_english', 'commute_time', 'health_uninsured', 'veteran', 'Ozone', 'PM25', 'N02', 'DiagPeriodL90D']\n",
            "['patient_race', 'payer_type', 'patient_state', 'patient_zip3', 'patient_gender', 'breast_cancer_diagnosis_code', 'breast_cancer_diagnosis_desc', 'metastatic_cancer_diagnosis_code', 'metastatic_first_novel_treatment', 'metastatic_first_novel_treatment_type', 'Region', 'Division']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "### Here combine both dfs\n",
        "preprocessor = make_column_transformer(\n",
        "    (make_pipeline(StandardScaler()), num_col),\n",
        "    (OneHotEncoder(), cat_col)\n",
        ")"
      ],
      "metadata": {
        "id": "Jgr3OdpKJfTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['DiagPeriodL90D']"
      ],
      "metadata": {
        "id": "MhzKaNZhJ8Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train.drop(columns=['DiagPeriodL90D'])\n",
        "test_X = test\n",
        "print(train_X.shape, test_X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuEh7S4qKBod",
        "outputId": "d8898361-b837-4ef8-ded8-b0d3a842a5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12906, 81) (5792, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_df = pd.concat([train_X, test_X], axis =0)\n",
        "whole_sparse = preprocessor.fit_transform(whole_df)\n",
        "whole_dense = whole_sparse.toarray()\n",
        "print(whole_dense.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XabW6QS5KF2S",
        "outputId": "120761a1-75e5-4d4f-a3d1-6df5bd8f4e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18698, 1056)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_dense = whole_dense[:12906, :]\n",
        "test_X_dense = whole_dense[12906:, :]"
      ],
      "metadata": {
        "id": "V9S48X30KY9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X_dense.shape, test_X_dense.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKTQ24CyLd1R",
        "outputId": "f70dc346-eda6-49a3-8bc5-2f080dff5db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12906, 1056) (5792, 1056)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wa-ixvcCZTv",
        "outputId": "801f684b-4cd2-4f06-a1dd-3b3e821d1d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Your data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_X_dense, y, test_size=0.25, stratify=y, random_state=66)\n",
        "\n",
        "def create_model(trial):\n",
        "    # Hyperparameters to be tuned\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
        "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "\n",
        "    # Model architecture\n",
        "    model = Sequential()\n",
        "    model.add(Dense(trial.suggest_int('units_first', 32, 256), activation=activation, input_dim=X_train.shape[1]))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    for i in range(n_layers):\n",
        "        num_units = trial.suggest_int(f'units_layer_{i+1}', 32, 256)\n",
        "        model.add(Dense(num_units, activation=activation))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "    # Compilation\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=5)\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_split=0.25,\n",
        "        epochs=50,  # May reduce for faster experimentation\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=0  # Set to 1 if you want to see the output\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # Increase n_trials for a more thorough search\n",
        "\n",
        "# Best trial results\n",
        "print(f'Number of finished trials: {len(study.trials)}')\n",
        "print(f'Best trial:')\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f'  Value: {trial.value}')\n",
        "print(f'  Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')\n",
        "\n",
        "# Rebuild and retrain the best model\n",
        "best_model = create_model(study.best_trial)\n",
        "best_model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)  # Retrain with more epochs if needed\n",
        "\n",
        "# Evaluate the best model\n",
        "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f'Best model accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQiDLeVAB_Cf",
        "outputId": "0df7ad8d-c4fd-4b19-e4d3-48f0fc3d338e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-24 20:39:20,915] A new study created in memory with name: no-name-4f7e0c2e-e859-4ae8-9934-3ae048208d83\n",
            "<ipython-input-38-1ca4adbe2711>:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2024-02-24 20:39:32,712] Trial 0 finished with value: 0.6244189739227295 and parameters: {'n_layers': 2, 'activation': 'sigmoid', 'dropout_rate': 0.21011389411491288, 'optimizer': 'sgd', 'learning_rate': 0.07749370961071209, 'units_first': 132, 'units_layer_1': 104, 'units_layer_2': 103}. Best is trial 0 with value: 0.6244189739227295.\n",
            "[I 2024-02-24 20:40:23,400] Trial 1 finished with value: 0.8044623732566833 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.31904654598718585, 'optimizer': 'sgd', 'learning_rate': 0.0031079964391018283, 'units_first': 73, 'units_layer_1': 149}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:40:30,770] Trial 2 finished with value: 0.6244189739227295 and parameters: {'n_layers': 3, 'activation': 'sigmoid', 'dropout_rate': 0.38017171643656, 'optimizer': 'sgd', 'learning_rate': 0.00021516727932650463, 'units_first': 170, 'units_layer_1': 69, 'units_layer_2': 118, 'units_layer_3': 83}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:40:45,826] Trial 3 finished with value: 0.800123929977417 and parameters: {'n_layers': 2, 'activation': 'relu', 'dropout_rate': 0.3286673475853865, 'optimizer': 'rmsprop', 'learning_rate': 0.0003009214756322916, 'units_first': 214, 'units_layer_1': 49, 'units_layer_2': 110}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:41:35,694] Trial 4 finished with value: 0.7883483171463013 and parameters: {'n_layers': 3, 'activation': 'tanh', 'dropout_rate': 0.2120922474381434, 'optimizer': 'sgd', 'learning_rate': 0.0005928308382945302, 'units_first': 216, 'units_layer_1': 201, 'units_layer_2': 211, 'units_layer_3': 76}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:41:47,617] Trial 5 finished with value: 0.7995041608810425 and parameters: {'n_layers': 2, 'activation': 'relu', 'dropout_rate': 0.4362596586294255, 'optimizer': 'adam', 'learning_rate': 0.0014207825725816516, 'units_first': 206, 'units_layer_1': 214, 'units_layer_2': 241}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:41:54,877] Trial 6 finished with value: 0.6244189739227295 and parameters: {'n_layers': 2, 'activation': 'relu', 'dropout_rate': 0.29092216485847927, 'optimizer': 'sgd', 'learning_rate': 0.003930227487986897, 'units_first': 34, 'units_layer_1': 86, 'units_layer_2': 83}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:42:07,304] Trial 7 finished with value: 0.7824605107307434 and parameters: {'n_layers': 1, 'activation': 'sigmoid', 'dropout_rate': 0.10446211227022557, 'optimizer': 'adam', 'learning_rate': 0.05993420039933714, 'units_first': 210, 'units_layer_1': 72}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:42:15,313] Trial 8 finished with value: 0.6244189739227295 and parameters: {'n_layers': 3, 'activation': 'sigmoid', 'dropout_rate': 0.35746331730904035, 'optimizer': 'rmsprop', 'learning_rate': 0.0005598816754268437, 'units_first': 218, 'units_layer_1': 89, 'units_layer_2': 51, 'units_layer_3': 187}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:42:26,539] Trial 9 finished with value: 0.7269909977912903 and parameters: {'n_layers': 2, 'activation': 'relu', 'dropout_rate': 0.15418383140466455, 'optimizer': 'rmsprop', 'learning_rate': 0.04580550157177044, 'units_first': 58, 'units_layer_1': 156, 'units_layer_2': 83}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:43:08,573] Trial 10 finished with value: 0.6070653796195984 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.4868647755236771, 'optimizer': 'sgd', 'learning_rate': 2.9398557561610758e-05, 'units_first': 97, 'units_layer_1': 152}. Best is trial 1 with value: 0.8044623732566833.\n",
            "[I 2024-02-24 20:43:30,157] Trial 11 finished with value: 0.8078711032867432 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.28493608656726593, 'optimizer': 'rmsprop', 'learning_rate': 6.54851730504974e-05, 'units_first': 146, 'units_layer_1': 37}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:44:10,560] Trial 12 finished with value: 0.8069414496421814 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.26778854063945684, 'optimizer': 'rmsprop', 'learning_rate': 1.1498019835730752e-05, 'units_first': 114, 'units_layer_1': 127}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:44:52,487] Trial 13 finished with value: 0.8069414496421814 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.23202882874126937, 'optimizer': 'rmsprop', 'learning_rate': 1.717618650535017e-05, 'units_first': 136, 'units_layer_1': 33}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:45:13,892] Trial 14 finished with value: 0.8063216805458069 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.2606129318995256, 'optimizer': 'rmsprop', 'learning_rate': 6.348389639748138e-05, 'units_first': 107, 'units_layer_1': 253}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:45:57,273] Trial 15 finished with value: 0.8069414496421814 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.40031860298270894, 'optimizer': 'rmsprop', 'learning_rate': 1.1593222659818176e-05, 'units_first': 170, 'units_layer_1': 119}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:46:22,218] Trial 16 finished with value: 0.8069414496421814 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.2741650258262919, 'optimizer': 'rmsprop', 'learning_rate': 5.559593921214811e-05, 'units_first': 177, 'units_layer_1': 202}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:46:43,862] Trial 17 finished with value: 0.8063216805458069 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.20245845620650338, 'optimizer': 'adam', 'learning_rate': 8.829343975997278e-05, 'units_first': 251, 'units_layer_1': 118}. Best is trial 11 with value: 0.8078711032867432.\n",
            "[I 2024-02-24 20:47:15,188] Trial 18 finished with value: 0.8097304105758667 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.13252729840177874, 'optimizer': 'rmsprop', 'learning_rate': 2.7793301752452672e-05, 'units_first': 117, 'units_layer_1': 178}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:47:37,615] Trial 19 finished with value: 0.8078711032867432 and parameters: {'n_layers': 2, 'activation': 'tanh', 'dropout_rate': 0.1025206368823312, 'optimizer': 'rmsprop', 'learning_rate': 0.00013904116171307187, 'units_first': 154, 'units_layer_1': 179, 'units_layer_2': 176}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:47:50,820] Trial 20 finished with value: 0.7926867008209229 and parameters: {'n_layers': 2, 'activation': 'tanh', 'dropout_rate': 0.1565941430712769, 'optimizer': 'rmsprop', 'learning_rate': 0.014185259616820252, 'units_first': 96, 'units_layer_1': 246, 'units_layer_2': 165}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:48:02,244] Trial 21 finished with value: 0.8069414496421814 and parameters: {'n_layers': 2, 'activation': 'tanh', 'dropout_rate': 0.10033405404589257, 'optimizer': 'rmsprop', 'learning_rate': 0.0001412712700204542, 'units_first': 154, 'units_layer_1': 176, 'units_layer_2': 168}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:48:44,539] Trial 22 finished with value: 0.8075612187385559 and parameters: {'n_layers': 3, 'activation': 'tanh', 'dropout_rate': 0.15064813957993672, 'optimizer': 'rmsprop', 'learning_rate': 4.186865192858724e-05, 'units_first': 148, 'units_layer_1': 179, 'units_layer_2': 205, 'units_layer_3': 246}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:48:59,059] Trial 23 finished with value: 0.8081809878349304 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.17032959659840105, 'optimizer': 'rmsprop', 'learning_rate': 0.00014507873450035638, 'units_first': 122, 'units_layer_1': 172}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:49:40,905] Trial 24 finished with value: 0.8081809878349304 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.159360462480606, 'optimizer': 'rmsprop', 'learning_rate': 2.294456618022786e-05, 'units_first': 126, 'units_layer_1': 228}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:50:04,184] Trial 25 finished with value: 0.8069414496421814 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.17236093662149157, 'optimizer': 'adam', 'learning_rate': 2.538147999453907e-05, 'units_first': 119, 'units_layer_1': 224}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:50:25,683] Trial 26 finished with value: 0.8078711032867432 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.13480388841409674, 'optimizer': 'rmsprop', 'learning_rate': 2.5631090649772044e-05, 'units_first': 77, 'units_layer_1': 226}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:50:38,410] Trial 27 finished with value: 0.8041524887084961 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.18747841276645044, 'optimizer': 'rmsprop', 'learning_rate': 0.00029859501822946603, 'units_first': 125, 'units_layer_1': 166}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:51:01,777] Trial 28 finished with value: 0.8063216805458069 and parameters: {'n_layers': 1, 'activation': 'sigmoid', 'dropout_rate': 0.23342309366555425, 'optimizer': 'rmsprop', 'learning_rate': 0.00011395551462626194, 'units_first': 91, 'units_layer_1': 192}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:51:45,009] Trial 29 finished with value: 0.8053920269012451 and parameters: {'n_layers': 1, 'activation': 'relu', 'dropout_rate': 0.12378489928459219, 'optimizer': 'adam', 'learning_rate': 1.0547437497466137e-05, 'units_first': 129, 'units_layer_1': 133}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:51:56,236] Trial 30 finished with value: 0.6244189739227295 and parameters: {'n_layers': 2, 'activation': 'sigmoid', 'dropout_rate': 0.18138471663776118, 'optimizer': 'rmsprop', 'learning_rate': 3.650426272095384e-05, 'units_first': 57, 'units_layer_1': 236, 'units_layer_2': 36}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:52:14,370] Trial 31 finished with value: 0.8084908723831177 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.1281834354613708, 'optimizer': 'rmsprop', 'learning_rate': 6.386391767670445e-05, 'units_first': 139, 'units_layer_1': 195}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:52:37,682] Trial 32 finished with value: 0.8072513341903687 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.127868820159893, 'optimizer': 'rmsprop', 'learning_rate': 2.1148481324034528e-05, 'units_first': 132, 'units_layer_1': 190}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:52:47,269] Trial 33 finished with value: 0.8084908723831177 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.22498835256869193, 'optimizer': 'rmsprop', 'learning_rate': 0.00020641160027296194, 'units_first': 189, 'units_layer_1': 213}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:53:00,017] Trial 34 finished with value: 0.8050821423530579 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.2290487437046537, 'optimizer': 'rmsprop', 'learning_rate': 0.0002643844258566855, 'units_first': 193, 'units_layer_1': 207}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:53:40,619] Trial 35 finished with value: 0.7923768162727356 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.20051686172474503, 'optimizer': 'sgd', 'learning_rate': 0.0009941705204852501, 'units_first': 188, 'units_layer_1': 162}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:53:55,027] Trial 36 finished with value: 0.8050821423530579 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.3178976714409842, 'optimizer': 'rmsprop', 'learning_rate': 0.00015705975581083474, 'units_first': 234, 'units_layer_1': 191}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:54:16,661] Trial 37 finished with value: 0.625038743019104 and parameters: {'n_layers': 1, 'activation': 'relu', 'dropout_rate': 0.12979380735853216, 'optimizer': 'sgd', 'learning_rate': 0.0005136465136160279, 'units_first': 163, 'units_layer_1': 141}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:54:28,045] Trial 38 finished with value: 0.6244189739227295 and parameters: {'n_layers': 2, 'activation': 'sigmoid', 'dropout_rate': 0.244771507662203, 'optimizer': 'rmsprop', 'learning_rate': 8.041880828845603e-05, 'units_first': 111, 'units_layer_1': 215, 'units_layer_2': 250}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:54:35,053] Trial 39 finished with value: 0.7970250844955444 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.17636654092334797, 'optimizer': 'adam', 'learning_rate': 0.0026586288445483107, 'units_first': 80, 'units_layer_1': 169}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:54:56,673] Trial 40 finished with value: 0.8022931218147278 and parameters: {'n_layers': 2, 'activation': 'relu', 'dropout_rate': 0.21800940023655846, 'optimizer': 'rmsprop', 'learning_rate': 0.00020470436214011626, 'units_first': 186, 'units_layer_1': 195, 'units_layer_2': 211}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:55:38,589] Trial 41 finished with value: 0.8069414496421814 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.16055675721598212, 'optimizer': 'rmsprop', 'learning_rate': 4.609774047046435e-05, 'units_first': 139, 'units_layer_1': 220}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:55:49,881] Trial 42 finished with value: 0.8032228350639343 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.1382780673607971, 'optimizer': 'rmsprop', 'learning_rate': 0.0004378854554910015, 'units_first': 162, 'units_layer_1': 239}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:56:04,402] Trial 43 finished with value: 0.8063216805458069 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.19215519189840252, 'optimizer': 'rmsprop', 'learning_rate': 0.00010190159786432506, 'units_first': 105, 'units_layer_1': 209}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:56:47,663] Trial 44 finished with value: 0.7985745072364807 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.16600730567262034, 'optimizer': 'sgd', 'learning_rate': 0.0011406571269426712, 'units_first': 122, 'units_layer_1': 233}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:57:21,320] Trial 45 finished with value: 0.8088007569313049 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.12311194333851004, 'optimizer': 'rmsprop', 'learning_rate': 1.80262105547034e-05, 'units_first': 142, 'units_layer_1': 178}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:57:27,319] Trial 46 finished with value: 0.6244189739227295 and parameters: {'n_layers': 1, 'activation': 'sigmoid', 'dropout_rate': 0.12022322608802674, 'optimizer': 'rmsprop', 'learning_rate': 1.4752178013493557e-05, 'units_first': 145, 'units_layer_1': 152}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:57:48,839] Trial 47 finished with value: 0.8060117959976196 and parameters: {'n_layers': 1, 'activation': 'tanh', 'dropout_rate': 0.11166640344222073, 'optimizer': 'rmsprop', 'learning_rate': 0.00019626530226847207, 'units_first': 175, 'units_layer_1': 175}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:58:18,877] Trial 48 finished with value: 0.8094205260276794 and parameters: {'n_layers': 3, 'activation': 'tanh', 'dropout_rate': 0.1399472465847443, 'optimizer': 'rmsprop', 'learning_rate': 3.818698255926335e-05, 'units_first': 201, 'units_layer_1': 186, 'units_layer_2': 132, 'units_layer_3': 158}. Best is trial 18 with value: 0.8097304105758667.\n",
            "[I 2024-02-24 20:59:01,258] Trial 49 finished with value: 0.625038743019104 and parameters: {'n_layers': 3, 'activation': 'relu', 'dropout_rate': 0.14714109828480948, 'optimizer': 'sgd', 'learning_rate': 3.606227807117597e-05, 'units_first': 206, 'units_layer_1': 187, 'units_layer_2': 139, 'units_layer_3': 155}. Best is trial 18 with value: 0.8097304105758667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 50\n",
            "Best trial:\n",
            "  Value: 0.8097304105758667\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    activation: tanh\n",
            "    dropout_rate: 0.13252729840177874\n",
            "    optimizer: rmsprop\n",
            "    learning_rate: 2.7793301752452672e-05\n",
            "    units_first: 117\n",
            "    units_layer_1: 178\n",
            "Epoch 1/100\n",
            "303/303 [==============================] - 2s 3ms/step - loss: 0.6632 - accuracy: 0.6043\n",
            "Epoch 2/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.6165 - accuracy: 0.6718\n",
            "Epoch 3/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.5853 - accuracy: 0.7301\n",
            "Epoch 4/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.5561 - accuracy: 0.7643\n",
            "Epoch 5/100\n",
            "303/303 [==============================] - 2s 5ms/step - loss: 0.5276 - accuracy: 0.7845\n",
            "Epoch 6/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.5099 - accuracy: 0.7935\n",
            "Epoch 7/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7967\n",
            "Epoch 8/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4892 - accuracy: 0.8032\n",
            "Epoch 9/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.8043\n",
            "Epoch 10/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4784 - accuracy: 0.8066\n",
            "Epoch 11/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.8071\n",
            "Epoch 12/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.8089\n",
            "Epoch 13/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.8092\n",
            "Epoch 14/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4704 - accuracy: 0.8093\n",
            "Epoch 15/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4695 - accuracy: 0.8097\n",
            "Epoch 16/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.8097\n",
            "Epoch 17/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4669 - accuracy: 0.8105\n",
            "Epoch 18/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4698 - accuracy: 0.8102\n",
            "Epoch 19/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.8105\n",
            "Epoch 20/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4672 - accuracy: 0.8106\n",
            "Epoch 21/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.8102\n",
            "Epoch 22/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.8105\n",
            "Epoch 23/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.8098\n",
            "Epoch 24/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4622 - accuracy: 0.8109\n",
            "Epoch 25/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4657 - accuracy: 0.8112\n",
            "Epoch 26/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4626 - accuracy: 0.8100\n",
            "Epoch 27/100\n",
            "303/303 [==============================] - 2s 5ms/step - loss: 0.4637 - accuracy: 0.8109\n",
            "Epoch 28/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4594 - accuracy: 0.8118\n",
            "Epoch 29/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4602 - accuracy: 0.8114\n",
            "Epoch 30/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.8095\n",
            "Epoch 31/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4602 - accuracy: 0.8105\n",
            "Epoch 32/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4593 - accuracy: 0.8120\n",
            "Epoch 33/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4588 - accuracy: 0.8110\n",
            "Epoch 34/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4600 - accuracy: 0.8117\n",
            "Epoch 35/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8106\n",
            "Epoch 36/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4593 - accuracy: 0.8111\n",
            "Epoch 37/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.8123\n",
            "Epoch 38/100\n",
            "303/303 [==============================] - 2s 5ms/step - loss: 0.4573 - accuracy: 0.8119\n",
            "Epoch 39/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.8117\n",
            "Epoch 40/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.8109\n",
            "Epoch 41/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.8117\n",
            "Epoch 42/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.8113\n",
            "Epoch 43/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.8125\n",
            "Epoch 44/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8120\n",
            "Epoch 45/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.8122\n",
            "Epoch 46/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4546 - accuracy: 0.8126\n",
            "Epoch 47/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8125\n",
            "Epoch 48/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4545 - accuracy: 0.8135\n",
            "Epoch 49/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4548 - accuracy: 0.8122\n",
            "Epoch 50/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4558 - accuracy: 0.8120\n",
            "Epoch 51/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4555 - accuracy: 0.8111\n",
            "Epoch 52/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4551 - accuracy: 0.8123\n",
            "Epoch 53/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.8118\n",
            "Epoch 54/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8121\n",
            "Epoch 55/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8125\n",
            "Epoch 56/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8113\n",
            "Epoch 57/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.8123\n",
            "Epoch 58/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4558 - accuracy: 0.8134\n",
            "Epoch 59/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4534 - accuracy: 0.8128\n",
            "Epoch 60/100\n",
            "303/303 [==============================] - 2s 5ms/step - loss: 0.4542 - accuracy: 0.8116\n",
            "Epoch 61/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.8124\n",
            "Epoch 62/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8123\n",
            "Epoch 63/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4540 - accuracy: 0.8126\n",
            "Epoch 64/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.8121\n",
            "Epoch 65/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4538 - accuracy: 0.8127\n",
            "Epoch 66/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4538 - accuracy: 0.8122\n",
            "Epoch 67/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8129\n",
            "Epoch 68/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8126\n",
            "Epoch 69/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8129\n",
            "Epoch 70/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4537 - accuracy: 0.8121\n",
            "Epoch 71/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.8138\n",
            "Epoch 72/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4522 - accuracy: 0.8118\n",
            "Epoch 73/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8130\n",
            "Epoch 74/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8127\n",
            "Epoch 75/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8130\n",
            "Epoch 76/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8131\n",
            "Epoch 77/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8126\n",
            "Epoch 78/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8125\n",
            "Epoch 79/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.8126\n",
            "Epoch 80/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.8130\n",
            "Epoch 81/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4506 - accuracy: 0.8140\n",
            "Epoch 82/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.8136\n",
            "Epoch 83/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8139\n",
            "Epoch 84/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4523 - accuracy: 0.8131\n",
            "Epoch 85/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4520 - accuracy: 0.8129\n",
            "Epoch 86/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8127\n",
            "Epoch 87/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8138\n",
            "Epoch 88/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8135\n",
            "Epoch 89/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8134\n",
            "Epoch 90/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4509 - accuracy: 0.8129\n",
            "Epoch 91/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.8128\n",
            "Epoch 92/100\n",
            "303/303 [==============================] - 1s 5ms/step - loss: 0.4500 - accuracy: 0.8131\n",
            "Epoch 93/100\n",
            "303/303 [==============================] - 2s 5ms/step - loss: 0.4512 - accuracy: 0.8127\n",
            "Epoch 94/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.8128\n",
            "Epoch 95/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4499 - accuracy: 0.8120\n",
            "Epoch 96/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8120\n",
            "Epoch 97/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4489 - accuracy: 0.8130\n",
            "Epoch 98/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8126\n",
            "Epoch 99/100\n",
            "303/303 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8130\n",
            "Epoch 100/100\n",
            "303/303 [==============================] - 1s 4ms/step - loss: 0.4499 - accuracy: 0.8139\n",
            "101/101 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8094\n",
            "Best model accuracy: 0.8094205260276794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train_X_dense and y are your entire training dataset and labels\n",
        "best_model.fit(train_X_dense, y, epochs=100, batch_size=64, verbose=1)  # You might adjust epochs and batch_size\n",
        "\n",
        "test_pred_probs = best_model.predict(test_X_dense)\n",
        "t1= pd.read_csv('./test.csv')\n",
        "print(test_pred_probs.shape, t1['patient_id'].shape)\n",
        "\n",
        "test_pred_probs_1d = test_pred_probs.flatten()\n",
        "# Assuming you have an ID column in your original test dataset to match the predictions\n",
        "# Create a DataFrame with IDs and the predicted probabilities\n",
        "submission_df1 = pd.DataFrame({\n",
        "    'patient_id': t1['patient_id'],\n",
        "    'DiagPeriodL90D': test_pred_probs_1d\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission_df1.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUxcYthNv-fy",
        "outputId": "7d0414fc-f6da-4ef8-acd4-7e6418ebf916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4578 - accuracy: 0.8122\n",
            "Epoch 2/100\n",
            "202/202 [==============================] - 1s 7ms/step - loss: 0.4581 - accuracy: 0.8116\n",
            "Epoch 3/100\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.4583 - accuracy: 0.8116\n",
            "Epoch 4/100\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.4567 - accuracy: 0.8118\n",
            "Epoch 5/100\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.4562 - accuracy: 0.8130\n",
            "Epoch 6/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.8104\n",
            "Epoch 7/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.8124\n",
            "Epoch 8/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4565 - accuracy: 0.8131\n",
            "Epoch 9/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8111\n",
            "Epoch 10/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.8122\n",
            "Epoch 11/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8129\n",
            "Epoch 12/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4560 - accuracy: 0.8115\n",
            "Epoch 13/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4554 - accuracy: 0.8116\n",
            "Epoch 14/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4554 - accuracy: 0.8116\n",
            "Epoch 15/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8127\n",
            "Epoch 16/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.8119\n",
            "Epoch 17/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8119\n",
            "Epoch 18/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4547 - accuracy: 0.8122\n",
            "Epoch 19/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.8120\n",
            "Epoch 20/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4546 - accuracy: 0.8130\n",
            "Epoch 21/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4553 - accuracy: 0.8132\n",
            "Epoch 22/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4545 - accuracy: 0.8116\n",
            "Epoch 23/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4555 - accuracy: 0.8120\n",
            "Epoch 24/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.8126\n",
            "Epoch 25/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8124\n",
            "Epoch 26/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8126\n",
            "Epoch 27/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4547 - accuracy: 0.8115\n",
            "Epoch 28/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4540 - accuracy: 0.8127\n",
            "Epoch 29/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.8115\n",
            "Epoch 30/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.8123\n",
            "Epoch 31/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8124\n",
            "Epoch 32/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.8124\n",
            "Epoch 33/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4530 - accuracy: 0.8129\n",
            "Epoch 34/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4533 - accuracy: 0.8127\n",
            "Epoch 35/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8121\n",
            "Epoch 36/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4530 - accuracy: 0.8125\n",
            "Epoch 37/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4544 - accuracy: 0.8119\n",
            "Epoch 38/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8119\n",
            "Epoch 39/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4524 - accuracy: 0.8128\n",
            "Epoch 40/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4529 - accuracy: 0.8118\n",
            "Epoch 41/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8127\n",
            "Epoch 42/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.8119\n",
            "Epoch 43/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4529 - accuracy: 0.8129\n",
            "Epoch 44/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8122\n",
            "Epoch 45/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8118\n",
            "Epoch 46/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.8126\n",
            "Epoch 47/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8121\n",
            "Epoch 48/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8133\n",
            "Epoch 49/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8123\n",
            "Epoch 50/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4511 - accuracy: 0.8128\n",
            "Epoch 51/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8132\n",
            "Epoch 52/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8130\n",
            "Epoch 53/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.8126\n",
            "Epoch 54/100\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.4519 - accuracy: 0.8130\n",
            "Epoch 55/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.8130\n",
            "Epoch 56/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8121\n",
            "Epoch 57/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.8127\n",
            "Epoch 58/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4513 - accuracy: 0.8123\n",
            "Epoch 59/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8126\n",
            "Epoch 60/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8130\n",
            "Epoch 61/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4510 - accuracy: 0.8128\n",
            "Epoch 62/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8135\n",
            "Epoch 63/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8127\n",
            "Epoch 64/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4510 - accuracy: 0.8126\n",
            "Epoch 65/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.8126\n",
            "Epoch 66/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8131\n",
            "Epoch 67/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4515 - accuracy: 0.8137\n",
            "Epoch 68/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8125\n",
            "Epoch 69/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4523 - accuracy: 0.8124\n",
            "Epoch 70/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4520 - accuracy: 0.8136\n",
            "Epoch 71/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8133\n",
            "Epoch 72/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.8126\n",
            "Epoch 73/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8122\n",
            "Epoch 74/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.8133\n",
            "Epoch 75/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.8123\n",
            "Epoch 76/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4505 - accuracy: 0.8133\n",
            "Epoch 77/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8135\n",
            "Epoch 78/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8140\n",
            "Epoch 79/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8135\n",
            "Epoch 80/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8126\n",
            "Epoch 81/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4524 - accuracy: 0.8130\n",
            "Epoch 82/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4496 - accuracy: 0.8115\n",
            "Epoch 83/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4511 - accuracy: 0.8127\n",
            "Epoch 84/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4523 - accuracy: 0.8122\n",
            "Epoch 85/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.8130\n",
            "Epoch 86/100\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4503 - accuracy: 0.8133\n",
            "Epoch 87/100\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.4508 - accuracy: 0.8126\n",
            "Epoch 88/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4514 - accuracy: 0.8122\n",
            "Epoch 89/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8132\n",
            "Epoch 90/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4491 - accuracy: 0.8130\n",
            "Epoch 91/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.8140\n",
            "Epoch 92/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4495 - accuracy: 0.8130\n",
            "Epoch 93/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8138\n",
            "Epoch 94/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4500 - accuracy: 0.8137\n",
            "Epoch 95/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4505 - accuracy: 0.8130\n",
            "Epoch 96/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.8137\n",
            "Epoch 97/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4491 - accuracy: 0.8126\n",
            "Epoch 98/100\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8133\n",
            "Epoch 99/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4500 - accuracy: 0.8130\n",
            "Epoch 100/100\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4495 - accuracy: 0.8137\n",
            "181/181 [==============================] - 0s 2ms/step\n",
            "(5792, 1) (5792,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X = train_df.drop('DiagPeriodL90D', axis=1)  # Replace 'diagonal90D' with your target column name\n",
        "# y = train_df['DiagPeriodL90D']"
      ],
      "metadata": {
        "id": "DvmqHtT4CeVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities on the test dataset\n",
        "test_pred_probs = best_model.predict(test_X_dense)\n",
        "t1= pd.read_csv('./test.csv')\n",
        "print(test_pred_probs.shape, t1['patient_id'].shape)\n",
        "\n",
        "test_pred_probs_1d = test_pred_probs.flatten()\n",
        "# Assuming you have an ID column in your original test dataset to match the predictions\n",
        "# Create a DataFrame with IDs and the predicted probabilities\n",
        "submission_df1 = pd.DataFrame({\n",
        "    'patient_id': t1['patient_id'],\n",
        "    'DiagPeriodL90D': test_pred_probs_1d\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission_df1.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olLlRcGpGPv2",
        "outputId": "eb52498b-6c5c-4cd0-aa5e-8f84d5934264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181/181 [==============================] - 0s 2ms/step\n",
            "(5792, 1) (5792,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'X' and 'y' are your features and labels respectively\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_X_dense, y, test_size=0.25, stratify=y, random_state=66)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "learning_rate = 0.001  # You can change this to whatever value you wish\n",
        "\n",
        "# Create an instance of the Adam optimizer with the desired learning rate\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model with additional metrics\n",
        "model.compile(optimizer=adam_optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[tf.keras.metrics.AUC(name='auc'), 'accuracy'])\n",
        "\n",
        "# Callbacks for early stopping (to prevent overfitting) and best model checkpointing\n",
        "# early_stopping = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=10)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_split=0.25,\n",
        "                    epochs=100,  # Adjust based on the convergence of your model\n",
        "                    batch_size=32,  # Adjust based on your preference and GPU memory\n",
        "                    callbacks=[model_checkpoint],\n",
        "                    verbose=1)\n",
        "\n",
        "# Load the best model saved by ModelCheckpoint\n",
        "best_model = tf.keras.models.load_model('best_model.h5')\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, auc, accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test AUC: {auc}, Test Accuracy: {accuracy}')\n",
        "\n",
        "# Predict probabilities on the test set for ROC-AUC score\n",
        "y_pred_probs = best_model.predict(X_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "print(f'Test ROC-AUC: {roc_auc}')\n"
      ],
      "metadata": {
        "id": "uRoOrgfWCpPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'X' and 'y' are your features and labels respectively\n",
        "# Make sure that 'train_X_dense' and 'y' are numpy arrays before you proceed\n",
        "# If they are not, convert them using np.array()\n",
        "\n",
        "n_splits = 5  # Number of folds\n",
        "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=66)\n",
        "test_predictions = np.zeros((test_X_dense.shape[0],))\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "\n",
        "for train, test in kfold.split(train_X_dense, y):\n",
        "    # Define the model architecture\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=train_X_dense.shape[1], activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "    ])\n",
        "\n",
        "    learning_rate = 0.001  # Adjust learning rate as needed\n",
        "    adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=adam_optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.AUC(name='auc'), 'accuracy'])\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(train_X_dense[train], y[train],\n",
        "                        validation_data=(train_X_dense[test], y[test]),\n",
        "                        callbacks=[early_stopping, model_checkpoint],\n",
        "                        epochs=100,  # Adjust based on the convergence of your model\n",
        "                        batch_size=64,  # Adjust based on your preference and GPU memory\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    scores = model.evaluate(train_X_dense[test], y[test], verbose=0)\n",
        "    test_pred = model.predict(test_X_dense)\n",
        "    test_predictions += test_pred.flatten()\n",
        "\n",
        "\n",
        "test_predictions /= n_splits\n",
        "\n",
        "# Optionally, compute a weighted average instead of a simple mean\n",
        "# weights = val_scores / np.sum(val_scores)\n",
        "# weighted_test_predictions = np.dot(test_predictions, weights)\n",
        "\n",
        "# Prepare the submission file\n",
        "t1 = pd.read_csv('./test.csv')  # Ensure this points to your test data\n",
        "submission_df = pd.DataFrame({\n",
        "    'patient_id': t1['patient_id'],\n",
        "    'DiagPeriodL90D': test_predictions  # Or use weighted_test_predictions\n",
        "})\n",
        "submission_df.to_csv('weighted_submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "JALU19HRUPnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the submission files\n",
        "sub1 = pd.read_csv('submission.csv')  # Assume this has columns 'patient_id' and 'DiagPeriodL90D'\n",
        "sub2 = pd.read_csv('submission (5).csv')  # Same structure\n",
        "# sub3 = pd.read_csv('weighted_submission.csv')  # Same structure\n",
        "\n",
        "# Check that 'patient_id' columns match across all submissions\n",
        "# This is crucial to ensure that predictions correspond to the same patients\n",
        "assert all(sub1['patient_id'] == sub2['patient_id']) #and all(sub1['patient_id'] == sub3['patient_id'])\n",
        "\n",
        "# Compute the weighted average of predictions\n",
        "final_predictions = 0.6 * sub1['DiagPeriodL90D'] + 0.4 * sub2['DiagPeriodL90D'] #+ 0.2 * sub3['DiagPeriodL90D']\n",
        "\n",
        "# Create the final submission file\n",
        "final_submission = pd.DataFrame({\n",
        "    'patient_id': sub1['patient_id'],\n",
        "    'DiagPeriodL90D': final_predictions\n",
        "})\n",
        "\n",
        "# Save the final submission file\n",
        "final_submission.to_csv('final_submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ZFePilvzTBTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zGLmdZ60DK_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCWDJfgQEBJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ege6tZGGHDec",
        "outputId": "6e206af9-0bcf-4a61-e7f4-757b4fa188f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12906, 292)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}